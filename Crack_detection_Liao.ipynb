{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bdd0c9-061a-42ef-acb9-0e826ef44637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.image import ssim\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, PReLU\n",
    "from keras.layers import Layer, Input, Conv2DTranspose, Cropping2D, BatchNormalization, ReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "# uploading and categorizing images in the dataset\n",
    "base_dir = #Write the path to the location you saved the dataset on your device\n",
    "images_dir = os.path.join(base_dir, 'Images')\n",
    "masks_dir = os.path.join(base_dir, 'Final_Masks', 'MasksG')\n",
    "heads_dir = os.path.join(base_dir, 'Final_Masks', 'Heads')\n",
    "train_file = os.path.join(base_dir, 'Final_Masks', 'train.txt')\n",
    "test_file = os.path.join(base_dir, 'Final_Masks', 'test.txt')\n",
    "\n",
    "def load_image(file_path):\n",
    "    image = img_to_array(load_img(file_path))\n",
    "    resized_image = tf.image.resize(image, [200, 200], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return resized_image\n",
    "\n",
    "def load_mask_or_head(file_path):\n",
    "    mask_or_head = img_to_array(load_img(file_path, color_mode='grayscale'))\n",
    "    resized_mask_or_head = tf.image.resize(mask_or_head, [200, 200] , method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return resized_mask_or_head\n",
    "    \n",
    "# Split the images according to train.txt and test.txt in CreckSeg9k \n",
    "with open(train_file, 'r') as f:\n",
    "    train_files = [line.strip() for line in f.readlines()]\n",
    "\n",
    "with open(test_file, 'r') as f:\n",
    "    test_files = [line.strip() for line in f.readlines()]\n",
    "\n",
    "trainX = np.array([load_image(os.path.join(images_dir, file)) for file in train_files])\n",
    "trainY_mask = np.array([load_mask_or_head(os.path.join(masks_dir, file)) for file in train_files])\n",
    "\n",
    "testX = np.array([load_image(os.path.join(images_dir, file)) for file in test_files])\n",
    "testY_mask = np.array([load_mask_or_head(os.path.join(masks_dir, file)) for file in test_files])\n",
    "\n",
    "trainY_mask = trainY_mask.reshape(trainY_mask.shape[0], trainY_mask.shape[1], trainY_mask.shape[2], 1)\n",
    "testY_mask = testY_mask.reshape(testY_mask.shape[0], testY_mask.shape[1], testY_mask.shape[2], 1)\n",
    "\n",
    "# Preprocessing\n",
    "x_train = trainX.astype('float32') / 255.0\n",
    "x_test = testX.astype('float32') / 255.0\n",
    "train_mask = trainY_mask.astype('float32') / 255.0\n",
    "test_mask = testY_mask.astype('float32') / 255.0\n",
    "\n",
    "# Plot a random image\n",
    "image = x_train[783]\n",
    "plt.imshow(image)\n",
    "image = x_train[783]\n",
    "mask1 = train_mask[783].squeeze()\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Image\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask1, cmap='gray')\n",
    "plt.title(\"Mask\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Training data shape: {x_train.shape}')\n",
    "print(f'Testing data shape: {x_test.shape}')\n",
    "print(f'Testing data shape: {train_mask.shape}')\n",
    "print(f'Testing data shape: {test_mask.shape}')\n",
    "\n",
    "def conv_block(x, filters, kernel_size=3, strides=1, dilation=1, padding='same'):\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, dilation_rate=dilation, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(x, filters, strides=1, dilation=1, padding='same'):\n",
    "    identity = x\n",
    "    x = conv_block(x, filters, kernel_size=3, strides=strides, dilation=dilation, padding=padding)\n",
    "    x = ReLU()(x)\n",
    "    x = conv_block(x, filters, kernel_size=3, strides=1, dilation=dilation, padding=padding)\n",
    "    shortcut = conv_block(identity, filters, kernel_size=3, strides=strides, dilation=dilation, padding=padding)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def LinkCrackNet(input_shape=(200, 200, 3)): \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Scale 1\n",
    "    x = conv_block(inputs, 32, kernel_size=3, strides=2, dilation=1, padding='same')\n",
    "    x = ReLU()(x)\n",
    "    print(f'Conv1_1 shape: {x.shape}')\n",
    "    x = conv_block(x, 64, kernel_size=3, strides=1, dilation=1, padding='same')\n",
    "    x = ReLU()(x)\n",
    "    print(f'Conv1_2 shape: {x.shape}')\n",
    "    skip1 = x  \n",
    "    print(f'skip1 shape: {skip1.shape}')\n",
    "    # Scale 2\n",
    "    x = residual_block(x, 64, strides=2 , dilation=1, padding='same')\n",
    "    x = residual_block(x, 64, strides=1 , dilation=1, padding='same')\n",
    "    x = residual_block(x, 64, strides=1 , dilation=1, padding='same')\n",
    "    print(f'Scale 2 shape: {x.shape}')\n",
    "    skip2 = x \n",
    "    print(f'skip2 shape: {skip2.shape}')\n",
    "    # Scale 3\n",
    "    x = residual_block(x, 64, strides=2 , dilation=1, padding='same') \n",
    "    x = residual_block(x, 64, strides=1 , dilation=1, padding='same')\n",
    "    x = residual_block(x, 64, strides=1 , dilation=1, padding='same')\n",
    "    x = residual_block(x, 64, strides=1 , dilation=1, padding='same')\n",
    "    print(f'Scale 3 shape: {x.shape}')\n",
    "    skip3 = x \n",
    "    print(f'skip3 shape: {skip3.shape}')\n",
    "    # Scale 4\n",
    "    x = residual_block(x, 128, strides=1 , dilation=1, padding='same')\n",
    "    x = residual_block(x, 128, strides=1 , dilation=1, padding='same')\n",
    "    x = residual_block(x, 128, strides=1 , dilation=1, padding='same')\n",
    "    x = residual_block(x, 128, strides=1 , dilation=2, padding='same')\n",
    "    x = residual_block(x, 128, strides=1 , dilation=2, padding='same')\n",
    "    x = residual_block(x, 128, strides=1 , dilation=2, padding='same')\n",
    "    print(f'Scale 4 shape: {x.shape}')\n",
    "    skip4 = x \n",
    "    print(f'skip4 shape: {skip4.shape}')\n",
    "    # Scale 4 (next layer)\n",
    "    x = residual_block(x, 128, strides=1 , dilation=2, padding='same') \n",
    "    x = residual_block(x, 128, strides=1 , dilation=4, padding='same') \n",
    "    x = residual_block(x, 128, strides=1 , dilation=4, padding='same') \n",
    "    print(f'Scale 4 next layer shape: {x.shape}')\n",
    "\n",
    "    ##### Decoding #####\n",
    "    # Scale 4\n",
    "    x = layers.add([x, skip4])\n",
    "    x = conv_block(x, 128, kernel_size=3, strides=1 , dilation=1, padding='same')  # Conv6_1\n",
    "    print(f'Conv6_1 shape: {x.shape}')\n",
    "    x = UpSampling2D()(x)\n",
    "    print(f'Conv6_1 UpSampling2D shape: {x.shape}')\n",
    "    x = conv_block(x, 64, kernel_size=3, strides=1 , dilation=1, padding='same')  # Conv6_2\n",
    "    print(f'Conv6_2 shape: {x.shape}')\n",
    "    # Scale 3\n",
    "    print(f'x shape: {x.shape}')\n",
    "    print(f'skip3 shape: {skip3.shape}')\n",
    "    x = layers.add([x, UpSampling2D()(skip3)])\n",
    "    x = conv_block(x, 64, kernel_size=3, strides=1 , dilation=1)  # Conv7_1\n",
    "    print(f'Conv7_1 shape: {x.shape}')\n",
    "    x = UpSampling2D()(x)\n",
    "    print(f'Conv7_1 UpSampling2D shape: {x.shape}')\n",
    "    x = conv_block(x, 64, kernel_size=3, strides=1 , dilation=1)  # Conv7_2\n",
    "    print(f'Conv7_2 shape: {x.shape}')\n",
    "    # Scale 2\n",
    "    print(f'x shape: {x.shape}')\n",
    "    print(f'skip3 shape: {skip2.shape}')\n",
    "    x = layers.add([x, UpSampling2D()(skip2)])\n",
    "    x = conv_block(x, 64, kernel_size=3, strides=1 , dilation=1)  # Conv8_1\n",
    "    print(f'Conv8_1 shape: {x.shape}')\n",
    "    x = UpSampling2D()(x)\n",
    "    x = conv_block(x, 64, kernel_size=3, strides=1 , dilation=1)  # Conv8_2\n",
    "    print(f'Conv8_2 shape: {x.shape}')\n",
    "\n",
    "    x = layers.add([x, UpSampling2D()(skip1)])\n",
    "    crack_prediction = Conv2D(32 , kernel_size=3, strides=1, activation='relu', padding='same')(x) # Conv9_1\n",
    "    print(f'Conv9_1 shape: {crack_prediction.shape}')\n",
    "    crack_prediction = Conv2D(1 , kernel_size=1, activation='sigmoid')(crack_prediction) # Conv9_2\n",
    "    print(f'Conv9_2 shape: {crack_prediction.shape}')\n",
    "\n",
    "    model = Model(inputs=inputs, outputs = crack_prediction)\n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    loss_function = 'binary_crossentropy'\n",
    "    optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])  \n",
    "    return model\n",
    "    \n",
    "model = LinkCrackNet(input_shape=(200, 200, 3))\n",
    "model = compile_model(model)\n",
    "model.summary()\n",
    "history = model.fit(x_train, train_mask, validation_data=(x_test, test_mask), epochs=20, batch_size=32)\n",
    "\n",
    "\n",
    "def plot_predictions(model, testX, test_mask, num_images=5):\n",
    "    random_indices = random.sample(range(testX.shape[0]), num_images)\n",
    "    \n",
    "    plt.figure(figsize=(15, num_images * 5))\n",
    "    \n",
    "    for i, idx in enumerate(random_indices):\n",
    "        test_image = np.expand_dims(testX[idx], axis=0)\n",
    "        \n",
    "        predicted_mask = model.predict(test_image)[0]\n",
    "        \n",
    "        plt.subplot(num_images, 3, i * 3 + 1)\n",
    "        plt.imshow(testX[idx])\n",
    "        plt.title(f\"Original Image {idx}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(num_images, 3, i * 3 + 2)\n",
    "        plt.imshow(predicted_mask.squeeze(), cmap='gray')\n",
    "        plt.title(f\"Predicted Mask {idx}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(num_images, 3, i * 3 + 3)\n",
    "        plt.imshow(test_mask[idx].squeeze(), cmap='gray')\n",
    "        plt.title(f\"Ground Truth Mask {idx}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(model, x_test, test_mask, num_images=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a0004-5a0f-46ca-a738-79652d590e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6077d-6304-4e04-ac42-97fc6eb27da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
